{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2sKwfPGzDVZ"
      },
      "source": [
        "## **Data Description**\n",
        "\n",
        "This dataset contains information on default payments, demographic factors, credit data, history of payment, and bill statements of credit card clients in Taiwan from **April 2005** to **September 2005.**\n",
        "\n",
        "\n",
        "### **Attribute Information:**\n",
        "\n",
        "There are 25 variables:\n",
        "\n",
        "*   ID: ID of each client\n",
        "*   LIMIT_BAL: Amount of given credit in NT dollars (includes individual and family/supplementary credit\n",
        "\n",
        "*   SEX: Gender (1=male, 2=female)\n",
        "*   EDUCATION: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)\n",
        "\n",
        "*   MARRIAGE: Marital status (1=married, 2=single, 3=others)\n",
        "*   AGE: Age in years\n",
        "\n",
        "*   PAY_0: Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month, 2=payment delay for two months, ... 8=payment delay for eight months, 9=payment delay for nine months and above)\n",
        "\n",
        "*   PAY_2: Repayment status in August, 2005 (scale same as above)\n",
        "\n",
        "*   PAY_3: Repayment status in July, 2005 (scale same as above)\n",
        "*   PAY_4: Repayment status in June, 2005 (scale same as above)\n",
        "\n",
        "\n",
        "*   PAY_5: Repayment status in May, 2005 (scale same as above)\n",
        "\n",
        "\n",
        "*   PAY_6: Repayment status in April, 2005 (scale same as above)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   BILL_AMT1: Amount of bill statement in September, 2005 (NT dollar)\n",
        "\n",
        "\n",
        "\n",
        "*   BILL_AMT2: Amount of bill statement in August, 2005 (NT dollar)\n",
        "*   BILL_AMT3: Amount of bill statement in July, 2005 (NT dollar)\n",
        "\n",
        "*   BILL_AMT4: Amount of bill statement in June, 2005 (NT dollar)\n",
        "*   BILL_AMT5: Amount of bill statement in May, 2005 (NT dollar)\n",
        "\n",
        "\n",
        "*   BILL_AMT6: Amount of bill statement in April, 2005 (NT dollar)\n",
        "\n",
        "*   PAY_AMT1: Amount of previous payment in September, 2005 (NT dollar)\n",
        "\n",
        "*   PAY_AMT2: Amount of previous payment in August, 2005 (NT dollar)\n",
        "*   PAY_AMT3: Amount of previous payment in July, 2005 (NT dollar)\n",
        "\n",
        "\n",
        "*   PAY_AMT4: Amount of previous payment in June, 2005 (NT dollar)\n",
        "\n",
        "\n",
        "*   PAY_AMT5: Amount of previous payment in May, 2005 (NT dollar)\n",
        "\n",
        "*   PAY_AMT6: Amount of previous payment in April, 2005 (NT dollar)\n",
        "*   default.payment.next.month: Default payment (1=yes, 0=no)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aikaMI-yxeMZ"
      },
      "source": [
        "# **Project Title :**\n",
        "\n",
        "# A Supervised Approach to Credit Card Fraud Detection Using Regression and Classification ML Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJUZghwi923m"
      },
      "source": [
        "\n",
        "# **Introduction**\n",
        "\n",
        "It is important that credit card companies can recognize fraudulent credit\n",
        "card transactions so that customers are not charged for items that they\n",
        "did not purchase.\n",
        "The Credit Card Fraud Detection Problem includes modelling past credit card\n",
        "transactions with the knowledge of the ones that turned out to be fraud. This\n",
        "model is then used to identify whether a new transaction is fraudulent or not. **Our aim here is to detect 100% of the fraudulent transactions while minimizing\n",
        "the incorrect fraud classifications.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFAaFqe9278u"
      },
      "source": [
        "## **Objective:**\n",
        "\n",
        "The notebook is structured as follows:\n",
        "\n",
        "*   First exploration: just to see what we have.  \n",
        "*   Cleaning: time to make choices about undocumented labels\n",
        "*   Feature engineering: time to be creative\n",
        "*   Final result and lessons learned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnVHzHwR9jD5"
      },
      "outputs": [],
      "source": [
        "# import basic libraries\n",
        "import pandas as pd\n",
        "pd.set_option(\"display.max_columns\", 100)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83J3YZH4FgUI",
        "outputId": "9b4bbe55-8396-45e0-ac3b-b5fb99bead9e"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "df = pd.read_excel(\"default of credit card clients.xlsx\")\n",
        "nRow, nCol = df.shape\n",
        "print(f'There are {nRow} row and {nCol} columns')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "rbG6_nn2FsYp",
        "outputId": "69fc418a-390e-43e2-87f7-f377e80200e0"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "fhvfABkeGLln",
        "outputId": "0c91d428-5d27-4479-882c-893b5471182e"
      },
      "outputs": [],
      "source": [
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfcHvcjTNT09",
        "outputId": "e121a946-9e3d-4633-887a-4f1d1b8c9390"
      },
      "outputs": [],
      "source": [
        "print(\"Shape of the Dataset : {}\".format(df.shape))\n",
        "print(\"Number of Columns in the Dataset : {}\".format(df.shape[1]))\n",
        "print(\"Number of Rows in the Dataset : {}\".format(df.shape[0]))\n",
        "print(\"-\"*40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0tCQO9DNcf8",
        "outputId": "f9c3fa1a-55bc-4aa7-f197-9b81c716d3d4"
      },
      "outputs": [],
      "source": [
        "numeric_features = df.select_dtypes(include = [np.number])\n",
        "categoric_features = df.select_dtypes(exclude = [np.number])\n",
        "print(\"Number of Numerical Features : {}\".format(numeric_features.shape[1]))\n",
        "print(\"Number of Categorical Features : {}\".format(categoric_features.shape[1]))\n",
        "print(\"-\"*40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4RIiqtJNgdS",
        "outputId": "ac91de80-4029-4caf-c513-aabafda0a95e"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OwZAFswNyg3",
        "outputId": "072be55e-f29e-4275-fd28-c245800efade"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum().max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgLiYMPaOCRw",
        "outputId": "20b35e64-ee31-4f43-9645-ef651839a48e"
      },
      "outputs": [],
      "source": [
        "print(\"No Fraud\", round(df['default payment next month'].value_counts()[0]/len(df) * 100,2), \"% of the dataset\")\n",
        "print(\"Fraud\", round(df['default payment next month'].value_counts()[1]/len(df) * 100,2), \"% of the dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otj9YomTukgB"
      },
      "source": [
        "# **Data Cleaning**\n",
        "\n",
        "> Indented block\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oi8-5a78YzP5",
        "outputId": "a55a4657-f6c7-462e-9b1d-b6e47948ee40"
      },
      "outputs": [],
      "source": [
        "fil = (df.EDUCATION == 5) | (df.EDUCATION == 6) | (df.EDUCATION == 0)\n",
        "df.loc[fil, 'EDUCATION'] = 4\n",
        "df.EDUCATION.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfrlGbdwY3Ma",
        "outputId": "5244e52b-b38b-411c-9562-4439831878c2"
      },
      "outputs": [],
      "source": [
        "df.loc[df.MARRIAGE == 0, 'MARRIAGE'] = 3\n",
        "df.MARRIAGE.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# renaming column for our convinience\n",
        "df.rename(columns = {'default payment next month': 'Isfraud'}, inplace = True)\n",
        "df.rename(columns = {'PAY_0': 'PAY_1'}, inplace = True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "FkFOsNO0ZwzP",
        "outputId": "2875a61f-b6bf-4801-b44a-b7cc4bc98946"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering\n",
        "\n",
        "1. Payment Status Aggregation: Instead of considering repayment status for each month separately, you could aggregate them to create new features such as:\n",
        "\n",
        "    * Average repayment status over the past few months.\n",
        "\n",
        "    * Maximum delay in repayment over the past few months.\n",
        "    \n",
        "    * Number of months with delayed payments.\n",
        "\n",
        "2. Bill Amount Difference: Calculate the difference between the bill amounts for consecutive months. This could indicate the trend in spending behavior over time.\n",
        "\n",
        "3. Bill Amount to Credit Limit Ratio: Calculate the ratio of bill amount to the credit limit for each month. This could provide insights into the credit utilization behavior of the clients.\n",
        "\n",
        "4. Age Binning: Instead of using age as a continuous variable, you could create age bins or categories to capture different age groups' behavior more effectively.\n",
        "\n",
        "5. Payment Amount Ratios: Calculate ratios such as the percentage of the bill amount paid each month compared to the total bill amount or the credit limit.\n",
        "\n",
        "6. Payment Amount Difference: Calculate the difference between the previous payment amount and the current bill amount. This could indicate how much of the outstanding balance is being paid off each month.\n",
        "\n",
        "7. Marriage Status Encoding: Encode the marriage status variable as binary indicators (e.g., married or not married) or group categories with fewer samples into an \"others\" category.\n",
        "\n",
        "8. Education Encoding: Encode the education variable into fewer categories by grouping similar levels together (e.g., graduate school and university into one category)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Feature engineering\n",
        "\n",
        "# Aggregating payment status over the past few months\n",
        "df['Avg_PAY'] = df[['PAY_1', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']].mean(axis=1)\n",
        "df['Max_Delay'] = df[['PAY_1', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']].max(axis=1)\n",
        "df['Num_Delay_Months'] = (df[['PAY_1', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']] > 0).sum(axis=1)\n",
        "\n",
        "# Calculating bill amount differences\n",
        "df['Bill_Amt_Diff_1'] = df['BILL_AMT1'] - df['BILL_AMT2']\n",
        "df['Bill_Amt_Diff_2'] = df['BILL_AMT2'] - df['BILL_AMT3']\n",
        "df['Bill_Amt_Diff_3'] = df['BILL_AMT3'] - df['BILL_AMT4']\n",
        "df['Bill_Amt_Diff_4'] = df['BILL_AMT4'] - df['BILL_AMT5']\n",
        "df['Bill_Amt_Diff_5'] = df['BILL_AMT5'] - df['BILL_AMT6']\n",
        "\n",
        "# Calculating bill amount to credit limit ratio\n",
        "df['Bill_Amt_to_Limit_Ratio'] = df['BILL_AMT1'] / df['LIMIT_BAL']\n",
        "\n",
        "# Binning age into categories\n",
        "bins = [20, 30, 40, 50, 60, 70, 80]\n",
        "labels = ['20-30', '30-40', '40-50', '50-60', '60-70', '70-80']\n",
        "df['Age_Group'] = pd.cut(df['AGE'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Encoding marriage status into binary indicators\n",
        "df['Married'] = df['MARRIAGE'].apply(lambda x: 1 if x == 1 else 0)\n",
        "\n",
        "# Encoding education into fewer categories\n",
        "df['Education'] = df['EDUCATION'].replace({4: 5, 5: 5, 6: 5})  # Grouping others and unknown categories into one\n",
        "\n",
        "# Calculating payment amount ratios\n",
        "df['Payment_Ratio_1'] = df['PAY_AMT1'] / df['BILL_AMT1']\n",
        "df['Payment_Ratio_2'] = df['PAY_AMT2'] / df['BILL_AMT2']\n",
        "df['Payment_Ratio_3'] = df['PAY_AMT3'] / df['BILL_AMT3']\n",
        "df['Payment_Ratio_4'] = df['PAY_AMT4'] / df['BILL_AMT4']\n",
        "df['Payment_Ratio_5'] = df['PAY_AMT5'] / df['BILL_AMT5']\n",
        "df['Payment_Ratio_6'] = df['PAY_AMT6'] / df['BILL_AMT6']\n",
        "\n",
        "# Calculating payment amount differences\n",
        "df['Payment_Amt_Diff_1'] = df['PAY_AMT1'] - df['BILL_AMT2']\n",
        "df['Payment_Amt_Diff_2'] = df['PAY_AMT2'] - df['BILL_AMT3']\n",
        "df['Payment_Amt_Diff_3'] = df['PAY_AMT3'] - df['BILL_AMT4']\n",
        "df['Payment_Amt_Diff_4'] = df['PAY_AMT4'] - df['BILL_AMT5']\n",
        "df['Payment_Amt_Diff_5'] = df['PAY_AMT5'] - df['BILL_AMT6']\n",
        "\n",
        "\n",
        "\n",
        "# Display the updated dataframe\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### One-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform one-hot encoding for 'Age_Group'\n",
        "df = pd.get_dummies(df, columns=['Age_Group'], drop_first=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Cleaning\n",
        "\n",
        "* Handling missing values: This involves identifying columns with missing values and deciding how to handle them. Common strategies include imputing missing values (replacing them with a statistical measure like the median, mean, or mode) or removing rows or columns with missing values.\n",
        "\n",
        "* Dealing with infinite values: Infinite values may arise during calculations or transformations. Converting infinite values to NaNs is a common practice, as NaNs can be easily handled using imputation or removal strategies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Replace infinite values with NaN\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Impute NaN values with the median of each feature\n",
        "df.fillna(df.median(), inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Scaling: \n",
        "\n",
        "* Scaling numerical features ensures that all features have a similar scale. MinMaxScaler is one of the scaling techniques that scales features to a specified range (commonly [0, 1])."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Initialize the MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit the scaler to your data and transform it\n",
        "df_scaled = scaler.fit_transform(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Building:\n",
        "\n",
        "* After preprocessing the data, you can proceed with training your machine learning model using the preprocessed features and target variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Finalizing Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = ['LIMIT_BAL', 'EDUCATION', 'MARRIAGE', 'PAY_1','PAY_2', 'PAY_3',\n",
        "            'PAY_4', 'PAY_5', 'PAY_6','BILL_AMT1', 'BILL_AMT2',\n",
        "            'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
        "            'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'Avg_PAY',\t'Max_Delay',\t\n",
        "            'Num_Delay_Months',\t'Bill_Amt_Diff_1',\t'Bill_Amt_Diff_2',\t'Bill_Amt_Diff_3',\t\n",
        "            'Bill_Amt_Diff_4',\t'Bill_Amt_Diff_5',\t'Bill_Amt_to_Limit_Ratio',\t\n",
        "            'Married', 'Education',\t'Payment_Ratio_1',\t'Payment_Ratio_2',\t'Payment_Ratio_3',\t\n",
        "            'Payment_Ratio_4',\t'Payment_Ratio_5',\t'Payment_Ratio_6',\t'Payment_Amt_Diff_1',\t\n",
        "            'Payment_Amt_Diff_2',\t'Payment_Amt_Diff_3',\t'Payment_Amt_Diff_4',\t'Payment_Amt_Diff_5']\n",
        "X = df[features].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, df['Isfraud'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isnull().sum().max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Balancing Data with Smote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Apply SMOTE to balance the dataset\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Logistic Regression\n",
        "logistic_model = LogisticRegression()\n",
        "logistic_model.fit(X_train_balanced, y_train_balanced)\n",
        "logistic_predictions = logistic_model.predict(X_test)\n",
        "\n",
        "# Decision Tree\n",
        "decision_tree_model = DecisionTreeClassifier()\n",
        "decision_tree_model.fit(X_train_balanced, y_train_balanced)\n",
        "decision_tree_predictions = decision_tree_model.predict(X_test)\n",
        "\n",
        "# Random Forest\n",
        "random_forest_model = RandomForestClassifier()\n",
        "random_forest_model.fit(X_train_balanced, y_train_balanced)\n",
        "random_forest_predictions = random_forest_model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Evaluation on Test_data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the models\n",
        "models = {\n",
        "    'Logistic Regression': logistic_predictions,\n",
        "    'Decision Tree': decision_tree_predictions,\n",
        "    'Random Forest': random_forest_predictions\n",
        "}\n",
        "\n",
        "for model_name, predictions in models.items():\n",
        "    print(f\"Confusion Matrix and Classification Report for {model_name}:\")\n",
        "    print(confusion_matrix(y_test, predictions))\n",
        "    print(classification_report(y_test, predictions))\n",
        "    print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the Random Forest classifier with the best hyperparameters\n",
        "best_rf_classifier = RandomForestClassifier(n_estimators=300, max_depth=None, min_samples_split=2, min_samples_leaf=1)\n",
        "\n",
        "# Train the Random Forest classifier on the balanced training data\n",
        "best_rf_classifier.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "# Now you can use the trained Random Forest classifier (best_rf_classifier) for making predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_rf_classifier.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PLot Learning Curve:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "# Define your model and parameters\n",
        "model = RandomForestClassifier(n_estimators=300, max_depth=None, min_samples_leaf=1, min_samples_split=2)\n",
        "\n",
        "# Plot learning curves\n",
        "train_sizes, train_scores, test_scores = learning_curve(model, X_train_balanced, y_train_balanced, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Calculate mean and standard deviation of training and validation scores\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "# Plot the learning curves\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_sizes, train_mean, label='Training score', color='blue')\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')\n",
        "plt.plot(train_sizes, test_mean, label='Validation score', color='red')\n",
        "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color='red')\n",
        "plt.xlabel('Number of training examples')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Learning curves')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CAP Analysis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_cap_curve(y_true, y_pred_proba, title=''):\n",
        "    total = len(y_true)\n",
        "    class_1_count = np.sum(y_true)\n",
        "    \n",
        "    sorted_proba_indices = np.argsort(y_pred_proba)[::-1]\n",
        "    y_sorted = y_true[sorted_proba_indices]\n",
        "    x = np.arange(1, total + 1)\n",
        "    y = np.cumsum(y_sorted) / class_1_count\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(x, y, marker='o', linestyle='-', color='b')\n",
        "    plt.plot([0, total], [0, 1], linestyle='--', color='r')\n",
        "    plt.xlabel('Total Observations')\n",
        "    plt.ylabel('Cumulative True Positive Rate')\n",
        "    plt.title(title)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Assuming best_rf_classifier is already trained and X_test, y_test are available\n",
        "y_pred_proba = best_rf_classifier.predict_proba(X_test)[:, 1]\n",
        "plot_cap_curve(y_test.values, y_pred_proba, title='CAP Curve for Random Forest Classifier')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperparameter Tuning using Grid Search Cross-Validation for Random Forest Classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define the parameter grid to search\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Create a Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier()\n",
        "\n",
        "# Define the GridSearchCV with k-fold cross-validation\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=kfold, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Perform the grid search\n",
        "grid_search.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "# Get the best hyperparameters and the best model\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Best Model:\", best_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Evaluation on Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Predictions on the training data\n",
        "y_train_pred = best_model.predict(X_train_balanced)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy_train = accuracy_score(y_train_balanced, y_train_pred)\n",
        "precision_train = precision_score(y_train_balanced, y_train_pred)\n",
        "recall_train = recall_score(y_train_balanced, y_train_pred)\n",
        "f1_score_train = f1_score(y_train_balanced, y_train_pred)\n",
        "confusion_matrix_train = confusion_matrix(y_train_balanced, y_train_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Performance Metrics on Training Data:\")\n",
        "print(\"Accuracy:\", accuracy_train)\n",
        "print(\"Precision:\", precision_train)\n",
        "print(\"Recall:\", recall_train)\n",
        "print(\"F1-score:\", f1_score_train)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
